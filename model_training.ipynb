{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be218796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1061 images belonging to 6 classes.\n",
      "Found 263 images belonging to 6 classes.\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 89s 3s/step - loss: 2.6210 - accuracy: 0.3032 - val_loss: 1.5362 - val_accuracy: 0.3984\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 78s 2s/step - loss: 1.4729 - accuracy: 0.3829 - val_loss: 1.5202 - val_accuracy: 0.3945\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 78s 2s/step - loss: 1.3513 - accuracy: 0.4742 - val_loss: 1.4024 - val_accuracy: 0.4258\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 78s 2s/step - loss: 1.2927 - accuracy: 0.4830 - val_loss: 1.3377 - val_accuracy: 0.4648\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 78s 2s/step - loss: 1.1735 - accuracy: 0.5471 - val_loss: 1.3351 - val_accuracy: 0.4648\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 78s 2s/step - loss: 1.1713 - accuracy: 0.5442 - val_loss: 1.2832 - val_accuracy: 0.4805\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.0891 - accuracy: 0.5743 - val_loss: 1.4463 - val_accuracy: 0.4141\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 82s 2s/step - loss: 1.1105 - accuracy: 0.5598 - val_loss: 1.3099 - val_accuracy: 0.4570\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 80s 2s/step - loss: 0.9901 - accuracy: 0.6336 - val_loss: 1.3975 - val_accuracy: 0.4883\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 82s 2s/step - loss: 0.8773 - accuracy: 0.6793 - val_loss: 1.2680 - val_accuracy: 0.4844\n",
      "9/9 [==============================] - 17s 2s/step\n",
      "Confusion Matrix\n",
      "[[13  3  0  0  3  5]\n",
      " [ 3 12  0  3  5 15]\n",
      " [ 7  0  1  0  4  3]\n",
      " [ 3  2  0 11  0 12]\n",
      " [ 4  5  0  7 11 29]\n",
      " [ 4  5  0  3  9 81]]\n",
      "\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Modhealthy       0.38      0.54      0.45        24\n",
      " Modinoculated       0.44      0.32      0.37        38\n",
      "    Reshealthy       1.00      0.07      0.12        15\n",
      " Resinoculated       0.46      0.39      0.42        28\n",
      "   Suschealthy       0.34      0.20      0.25        56\n",
      "Suscinoculated       0.56      0.79      0.66       102\n",
      "\n",
      "      accuracy                           0.49       263\n",
      "     macro avg       0.53      0.38      0.38       263\n",
      "  weighted avg       0.49      0.49      0.45       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "DATA_FOLDER = 'final_data'\n",
    "IMG_SIZE = (224, 224)  # Adjust based on ResNet50 requirements\n",
    "BATCH_SIZE = 32  # Can be adjusted based on your system's capabilities\n",
    "\n",
    "# Cell 2: Prepare Data\n",
    "def prepare_data(data_folder, img_size, batch_size):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_folder,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        data_folder,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False  # Important for correct label ordering in evaluation\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "# Cell 3: Set Up ResNet50 Model for Transfer Learning\n",
    "def setup_model(train_data, img_size):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)  # Adjust the size of the dense layer if needed\n",
    "    predictions = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "# Cell 4: Compile and Train the Model\n",
    "def compile_and_train_model(model, train_data, val_data):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        steps_per_epoch=train_data.samples // train_data.batch_size,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=val_data.samples // val_data.batch_size,\n",
    "        epochs=10  # Adjust the number of epochs\n",
    "    )\n",
    "    return history\n",
    "\n",
    "# Cell 5: Evaluate the Model\n",
    "def evaluate_model(model, val_data):\n",
    "    val_predictions = model.predict(val_data)\n",
    "    val_labels = np.argmax(val_predictions, axis=1)\n",
    "    true_labels = val_data.classes\n",
    "    class_labels = list(val_data.class_indices.keys())\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(true_labels, val_labels))\n",
    "\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(true_labels, val_labels, target_names=class_labels))\n",
    "\n",
    "# Cell 6: Main Function to Run the Workflow\n",
    "def main():\n",
    "    train_generator, validation_generator = prepare_data(DATA_FOLDER, IMG_SIZE, BATCH_SIZE)\n",
    "    model = setup_model(train_generator, IMG_SIZE)\n",
    "    compile_and_train_model(model, train_generator, validation_generator)\n",
    "    evaluate_model(model, validation_generator)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cafd7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1061 images belonging to 6 classes.\n",
      "Found 263 images belonging to 6 classes.\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 447s 13s/step - loss: 3.7095 - accuracy: 0.2653 - val_loss: 1.5615 - val_accuracy: 0.3828\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 350s 11s/step - loss: 2.1309 - accuracy: 0.3392 - val_loss: 1.3818 - val_accuracy: 0.4570\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 273s 8s/step - loss: 1.5581 - accuracy: 0.4004 - val_loss: 1.3339 - val_accuracy: 0.4570\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 257s 8s/step - loss: 1.3439 - accuracy: 0.4684 - val_loss: 1.4314 - val_accuracy: 0.3711\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 226s 7s/step - loss: 1.2918 - accuracy: 0.4781 - val_loss: 1.3451 - val_accuracy: 0.4219\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 243s 7s/step - loss: 1.2186 - accuracy: 0.4927 - val_loss: 1.3042 - val_accuracy: 0.4531\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 240s 7s/step - loss: 1.1803 - accuracy: 0.5423 - val_loss: 1.2403 - val_accuracy: 0.4531\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 241s 7s/step - loss: 1.1488 - accuracy: 0.5530 - val_loss: 1.2108 - val_accuracy: 0.5195\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 222s 7s/step - loss: 1.0941 - accuracy: 0.5695 - val_loss: 1.1596 - val_accuracy: 0.5117\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 216s 7s/step - loss: 1.0553 - accuracy: 0.5996 - val_loss: 1.1918 - val_accuracy: 0.5312\n",
      "9/9 [==============================] - 46s 5s/step\n",
      "Confusion Matrix\n",
      "[[ 3  6  4  2  4  5]\n",
      " [ 4  6  5  2  7 14]\n",
      " [ 2  2  1  2  5  3]\n",
      " [ 3  3  3  6  6  7]\n",
      " [ 7  9  2  5 14 19]\n",
      " [13 20  8  7 15 39]]\n",
      "\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Modhealthy       0.09      0.12      0.11        24\n",
      " Modinoculated       0.13      0.16      0.14        38\n",
      "    Reshealthy       0.04      0.07      0.05        15\n",
      " Resinoculated       0.25      0.21      0.23        28\n",
      "   Suschealthy       0.27      0.25      0.26        56\n",
      "Suscinoculated       0.45      0.38      0.41       102\n",
      "\n",
      "      accuracy                           0.26       263\n",
      "     macro avg       0.21      0.20      0.20       263\n",
      "  weighted avg       0.29      0.26      0.27       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "DATA_FOLDER = 'final_data'  # Directory with preprocessed and augmented data\n",
    "IMG_SIZE = (224, 224)  # VGG16 standard image size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Function for Preparing Data\n",
    "def prepare_data():\n",
    "    # Preprocessing the input \n",
    "    datagen = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input, validation_split=0.2)\n",
    "\n",
    "    # Prepare generators\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        DATA_FOLDER,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        DATA_FOLDER,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "# Function to Build and Compile the VGG16 Model\n",
    "def build_vgg16_model(train_data):\n",
    "    # Load the VGG16 model, pre-trained on ImageNet data\n",
    "    vgg16_base = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "\n",
    "    # Freeze the layers\n",
    "    for layer in vgg16_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top for our specific task\n",
    "    x = vgg16_base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Dropout added\n",
    "    predictions = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=vgg16_base.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to Train and Evaluate the Model\n",
    "def train_and_evaluate(model, train_generator, validation_generator):\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "        epochs=10  # Adjust as needed\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_predictions = model.predict(validation_generator)\n",
    "    val_labels = np.argmax(val_predictions, axis=1)\n",
    "    true_labels = validation_generator.classes\n",
    "    class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(true_labels, val_labels))\n",
    "\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(true_labels, val_labels, target_names=class_labels))\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    train_generator, validation_generator = prepare_data()\n",
    "    vgg16_model = build_vgg16_model(train_generator)\n",
    "    train_and_evaluate(vgg16_model, train_generator, validation_generator)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461e6919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1061 images belonging to 6 classes.\n",
      "Found 263 images belonging to 6 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-mobile-no-top.h5\n",
      "19993432/19993432 [==============================] - 7s 0us/step\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 50s 1s/step - loss: 1.9343 - accuracy: 0.3071 - val_loss: 1.6076 - val_accuracy: 0.3242\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 39s 1s/step - loss: 1.5758 - accuracy: 0.3790 - val_loss: 1.4976 - val_accuracy: 0.4180\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 40s 1s/step - loss: 1.5465 - accuracy: 0.3878 - val_loss: 1.5464 - val_accuracy: 0.3203\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 39s 1s/step - loss: 1.4421 - accuracy: 0.4344 - val_loss: 1.5556 - val_accuracy: 0.3242\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 39s 1s/step - loss: 1.4730 - accuracy: 0.3955 - val_loss: 1.4709 - val_accuracy: 0.3828\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 39s 1s/step - loss: 1.4121 - accuracy: 0.4325 - val_loss: 1.4411 - val_accuracy: 0.4531\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 40s 1s/step - loss: 1.3641 - accuracy: 0.4431 - val_loss: 1.4956 - val_accuracy: 0.3867\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 45s 1s/step - loss: 1.3644 - accuracy: 0.4470 - val_loss: 1.5023 - val_accuracy: 0.3672\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 42s 1s/step - loss: 1.3207 - accuracy: 0.4706 - val_loss: 1.4794 - val_accuracy: 0.3906\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 42s 1s/step - loss: 1.3095 - accuracy: 0.4820 - val_loss: 1.4484 - val_accuracy: 0.4141\n",
      "9/9 [==============================] - 12s 950ms/step\n",
      "Confusion Matrix\n",
      "[[ 1  4  0  0 12  7]\n",
      " [ 1  3  0  0 22 12]\n",
      " [ 1  1  0  0  6  7]\n",
      " [ 3  1  0  2 12 10]\n",
      " [ 2  7  0  0 28 19]\n",
      " [ 4  8  3  0 52 35]]\n",
      "\n",
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Modhealthy       0.08      0.04      0.06        24\n",
      " Modinoculated       0.12      0.08      0.10        38\n",
      "    Reshealthy       0.00      0.00      0.00        15\n",
      " Resinoculated       1.00      0.07      0.13        28\n",
      "   Suschealthy       0.21      0.50      0.30        56\n",
      "Suscinoculated       0.39      0.34      0.36       102\n",
      "\n",
      "      accuracy                           0.26       263\n",
      "     macro avg       0.30      0.17      0.16       263\n",
      "  weighted avg       0.33      0.26      0.24       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import nasnet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "DATA_FOLDER = 'final_data'  # Directory with preprocessed and augmented data\n",
    "IMG_SIZE = (224, 224)  # Adjust as per NASNetMobile requirements\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Function for Preparing Data\n",
    "def prepare_data():\n",
    "    # Preprocessing the input \n",
    "    datagen = ImageDataGenerator(preprocessing_function=nasnet.preprocess_input, validation_split=0.2)\n",
    "\n",
    "    # Prepare generators\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        DATA_FOLDER,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        DATA_FOLDER,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "# Function to Build and Compile the NASNetMobile Model\n",
    "def build_nasnet_model(train_data):\n",
    "    # Load the NASNetMobile model, pre-trained on ImageNet data\n",
    "    nasnet_base = nasnet.NASNetMobile(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\n",
    "\n",
    "    # Freeze the layers\n",
    "    for layer in nasnet_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top for our specific task\n",
    "    x = nasnet_base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Dropout added\n",
    "    predictions = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Compile the model\n",
    "    model = Model(inputs=nasnet_base.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to Train and Evaluate the Model\n",
    "def train_and_evaluate(model, train_generator, validation_generator):\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "        epochs=10  # Adjust as needed\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_predictions = model.predict(validation_generator)\n",
    "    val_labels = np.argmax(val_predictions, axis=1)\n",
    "    true_labels = validation_generator.classes\n",
    "    class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(true_labels, val_labels))\n",
    "\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(true_labels, val_labels, target_names=class_labels))\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    train_generator, validation_generator = prepare_data()\n",
    "    nasnet_model = build_nasnet_model(train_generator)\n",
    "    train_and_evaluate(nasnet_model, train_generator, validation_generator)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ff660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
